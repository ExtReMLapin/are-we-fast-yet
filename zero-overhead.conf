# -*- mode: yaml -*-
# Config file for ReBench
standard_experiment: all
standard_data_file: 'zero-overhead.data'

# settings and requirements for statistic evaluation
statistics:
    confidence_level: 0.95

runs:
    number_of_data_points: 100

# settings for quick runs, useful for fast feedback during experiments
quick_runs:
    number_of_data_points: 3
    max_time: 60   # time in seconds

# definition of benchmark suites
benchmark_suites:
    macro-steady:
        gauge_adapter: RebenchLog
        command: &MACRO_COMMAND " -cp Smalltalk:Examples/Benchmarks/Richards:Examples/Benchmarks/DeltaBlue:Examples/Benchmarks/NBody Examples/Benchmarks/BenchmarkHarness.som  %(benchmark)s "
        max_runtime: 60000
        benchmarks:
            - Richards:
                extra_args: "400 0 100"
                warmup: 0
            - DeltaBlue:
                extra_args: "400 0 6000"
                warmup: 0
            - Mandelbrot:
                extra_args: "400 0 1000"
                warmup: 0
            - NBody:
                extra_args: "400 0 250000"
                warmup: 0
    macro-startup:
        gauge_adapter: RebenchLog
        command: *MACRO_COMMAND
        max_runtime: 60000
        benchmarks:
            - Richards:
                extra_args: "1 0 100"
            - DeltaBlue:
                extra_args: "1 0 10000"
            - Mandelbrot:
                extra_args: "1 0 1000"
            - NBody:
                extra_args: "1 0 250000"

    # macro-steady-java:
    #     gauge_adapter: RebenchLog
    #     location: implementations/classic-benchmarks/
    #     command: " %(benchmark)s "
    #     max_runtime: 600
    #     benchmarks:
    #         - Richards:
    #             extra_args: "104 0 100"
    #             warmup: 4
    #         - DeltaBlue:
    #             extra_args: "103 0 10000"
    #             warmup: 3
    #         - Mandelbrot:
    #             extra_args: "1000 110"
    #             warmup: 10

    # macro-steady-pypy:
    #     gauge_adapter: RebenchLog
    #     location: implementations/classic-benchmarks/benchmarks/
    #     command: " %(benchmark)s "
    #     max_runtime: 600
    #     benchmarks:
    #         - Richards:
    #             command:    richards.py
    #             extra_args: "110 0 100"
    #             warmup: 10
    #         - DeltaBlue:
    #             command:    deltablue.py
    #             extra_args: "103 0 10000"
    #             warmup: 3
    #         - Mandelbrot:
    #             command:    mandelbrot.py
    #             extra_args: "1000 110"
    #             warmup: 10

    micro-steady:
        gauge_adapter: RebenchLog
        command: " -cp Smalltalk Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 60000
        benchmarks:
            - Bounce:
                extra_args: "150 0 200"
                warmup: 0
            - BubbleSort:
                extra_args: "150 0 300"
                warmup: 0
            - Dispatch:
                extra_args: "150 0 2000"
                warmup: 0
            - Fannkuch:
                extra_args: "150 0 8"
                warmup: 0
            - Fibonacci:
                extra_args: "150 0 300"
                warmup: 0
            - FieldLoop:
                extra_args: "150 0 300"
                warmup: 0
            - IntegerLoop:
                extra_args: "150 0 800"
                warmup: 0
            - List:
                extra_args: "150 0 200"
                warmup: 0
            - Loop:
                extra_args: "150 0 1000"
                warmup: 0
            - Permute:
                extra_args: "150 0 300"
                warmup: 0
            - Queens:
                extra_args: "150 0 200"
                warmup: 0
            - QuickSort:
                extra_args: "150 0 300"
                warmup: 0
            - Recurse:
                extra_args: "150 0 300"
                warmup: 0
            - Sieve:
                extra_args: "150 0 500"
                warmup: 0
            - Storage:
                extra_args: "150 0 200"
                warmup: 0
            - Sum:
                extra_args: "150 0 1000"
                warmup: 0
            - Towers:
                extra_args: "150 0 200"
                warmup: 0
            - TreeSort:
                extra_args: "150 0 100"
                warmup: 0
            - WhileLoop:
                extra_args: "150 0 3000"
                warmup: 0
    reflection:
        gauge_adapter: RebenchLog
        command: " -cp Smalltalk:Examples/Benchmarks/DoesNotUnderstand Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 60000
        benchmarks:
            - DirectAdd:
                extra_args: 150 0 2000
                warmup: 0
            - DnuAdd:
                extra_args: 150 0 2000
                warmup: 0
            - DnuPerformAdd:
                extra_args: 150 0 2000
                warmup: 0
            - PerformAdd:
                extra_args: 150 0 2000
                warmup: 0
    proxy:
        gauge_adapter: RebenchLog
        command: " -cp Smalltalk:Examples/Benchmarks/DoesNotUnderstand Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 60000
        benchmarks:
            - ProxyAdd:
                extra_args: 150 0 2000
                warmup: 0
            - IndirectAdd:
                extra_args: 150 0 2000
                warmup: 0            
    
    omop:
        gauge_adapter: RebenchLog
        command: " -cp Smalltalk:Examples/Benchmarks/OMOP Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 60000
        benchmarks:
            - AddDispatch:
                extra_args: 150 0 2000
                warmup: 0
            - AddDispatchEnforced:
                extra_args: 150 0 2000
                warmup: 0
            - AddFieldWrite:
                extra_args: 150 0 2000
                warmup: 0
            - AddFieldWriteEnforced:
                extra_args: 150 0 2000
                warmup: 0
            - Dispatch:
                extra_args: 150 0 2000
                warmup: 0
            - DispatchEnforced:
                extra_args: 150 0 2000
                warmup: 0
            - DispatchEnforcedStd:
                extra_args: 150 0 2000
                warmup: 0
            - FieldRead:
                extra_args: 150 0 2000
                warmup: 0
            - FieldReadEnforced:
                extra_args: 150 0 2000
                warmup: 0
            - GlobalRead:
                extra_args: 150 0 2000
                warmup: 0
            - GlobalReadEnforced:
                extra_args: 150 0 2000
                warmup: 0
            - ReqPrim:
                extra_args: 150 0 2000
                warmup: 0
            - ReqPrimEnforced:
                extra_args: 150 0 2000
                warmup: 0
    JavaReflection:
        location: .
        gauge_adapter: JMH
        command: -jar implementations/cost-of-reflection/java/reflection/target/microbenchmarks.jar -wi 3 -i 25 -f 4 %(benchmark)s
        benchmarks:
            - benchmarks.DynamicProxy.directAdd
            - benchmarks.DynamicProxy.proxiedAdd
            - benchmarks.MethodInvocation.testDirectCall
            - benchmarks.MethodInvocation.testReflectiveCallFromMutableVar
            - benchmarks.MethodInvocation.testReflectiveCallFromFinalVar
            - benchmarks.MethodInvocation.testReflectiveCallFromStaticFinalVar
            - benchmarks.MethodInvocation.testHandleCallFromMutableVar
            - benchmarks.MethodInvocation.testHandleCallFromFinalVar
            - benchmarks.MethodInvocation.testHandleCallFromStaticFinalVar
    PyPyReflection:
        location: .
        gauge_adapter: RebenchLog
        command: implementations/cost-of-reflection/python/%(benchmark)s
        benchmarks:
            - OMOPDirect:
                command: mini_omop.py Direct
                extra_args: &PyOmopArgs 100 0 1000
            - OMOPProxy:
                command: mini_omop.py Proxy
                extra_args: *PyOmopArgs
            - MethodDirect:
                command: method_invocation.py Direct
                extra_args: &PyMethArgs 100 0 1000
            - MethodDirectStatic:
                command: method_invocation.py DirectStatic
                extra_args: *PyMethArgs
            - MethodReflectiveBound:
                command: method_invocation.py ReflectiveBound
                extra_args: *PyMethArgs
            - MethodReflectiveUnbound:
                command: method_invocation.py ReflectiveUnbound
                extra_args: *PyMethArgs
            - MethodReflectiveStaticBound:
                command: method_invocation.py ReflectiveStaticBound
                extra_args: *PyMethArgs
            - MethodReflectiveStaticUnbound:
                command: method_invocation.py ReflectiveStaticUnbound
                extra_args: *PyMethArgs
            - DynamicProxy:
                command: dynamic_proxy.py Proxy
                extra_args: &PyProxyArgs 100 0 1000
            - DynamicDirect:
                command: dynamic_proxy.py Direct
                extra_args: *PyProxyArgs

# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    Java:
        path: /usr/bin/
        binary: java
        args: "-server "
    # Java-Int:
    #     path: /usr/bin/
    #     binary: java
    #     args: -Xint
    PyPy:
        path: /usr/bin/
        binary: env
        args: "pypy "
    # TruffleSOM-interpreter:
    #     path: TruffleSOM
    #     binary: som.sh
    #     args: ""
    TruffleSOM-graal-old-splitting:
        path: implementations/TruffleSOM
        binary: ../graal.sh
        args: " -G:+TruffleSplitting -G:-TraceTruffleInlining -G:-TraceTruffleCompilation -Xbootclasspath/a:build/classes:../graal/truffle.jar som.vm.Universe"    
    TruffleSOM-graal:
        path: implementations/TruffleSOM
        binary: ../graal.sh
        args: " -G:+TruffleSplittingNew -G:-TraceTruffleInlining -G:-TraceTruffleCompilation -Xbootclasspath/a:build/classes:../graal/truffle.jar som.vm.Universe"
    TruffleSOM-graal-split-extra:
        path: implementations/TruffleSOM
        binary: ../graal.sh
        args: " -G:+TruffleSplittingNew -G:-TruffleSplittingClassInstanceStamps -G:-TraceTruffleInlining -G:-TraceTruffleCompilation -Xbootclasspath/a:build/classes:../graal/truffle.jar som.vm.Universe"
    TruffleSOM-graal-no-split:
        path: implementations/TruffleSOM
        binary: ../graal.sh
        args: " -G:-TruffleSplitting -G:-TraceTruffleInlining -G:-TraceTruffleCompilation -Xbootclasspath/a:build/classes:../graal/truffle.jar som.vm.Universe"
    TruffleSOM-OMOP-graal:
        path: implementations/TruffleSOM-OMOP
        binary: ../graal.sh
        args: " -G:+TruffleSplittingNew -G:-TraceTruffleInlining -G:-TraceTruffleCompilation -Xbootclasspath/a:build/classes:../graal/truffle.jar som.vm.Universe"


    # RPySOM-interpreter:
    #     path: .
    #     binary: RPySOM-no-jit
    #     args: "-cp Smalltalk"
    # RPySOM-non-recursive-jit:
    #     path: RPySOM-non-recursive
    #     binary: RPySOM-jit
    #     args: ""
    RTruffleSOM-jit:
        path: implementations/RTruffleSOM
        binary: RTruffleSOM-jit
        args: ""
    RTruffleSOM-OMOP-jit:
        path: implementations/RTruffleSOM-OMOP
        binary: RTruffleSOM-jit
        args: ""
    SOMpp:
        path: implementations/SOMpp
        binary: som.sh
        args: ""
    # CogVM:
    #     path: .
    #     binary: pharo.sh

# define the benchmarks to be executed for a re-executable benchmark run
experiments:
    # Java:
    #     actions:    benchmark
    #     benchmark:  macro-steady-java
    #     executions:
    #         - Java
    # LuaJIT:
    #     actions:    benchmark
    #     benchmark:  macro-steady-lua
    #     executions: LuaJIT
    # PyPy:
    #     actions:    benchmark
    #     benchmark:  macro-steady-pypy
    #     executions: PyPy
    SOM:
        description: All benchmarks on SOM
        actions: benchmark
        benchmark:
            - macro-steady
            - micro-steady
            - reflection
        executions:
            - TruffleSOM-graal
            - TruffleSOM-graal-no-split
            - TruffleSOM-graal-split-extra
            - TruffleSOM-graal-old-splitting
            - RTruffleSOM-jit
            - TruffleSOM-OMOP-graal
            - RTruffleSOM-OMOP-jit
    OMOP:
        actions: benchmark
        benchmark:
            - omop
        executions:
            - TruffleSOM-OMOP-graal
            - RTruffleSOM-OMOP-jit
    JavaReflection:
        actions: benchmark
        benchmark: JavaReflection
        executions: Java
    PyPyReflection:
        actions: benchmark
        benchmark: PyPyReflection
        executions: PyPy
